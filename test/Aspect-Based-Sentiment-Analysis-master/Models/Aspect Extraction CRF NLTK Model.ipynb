{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating List of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Generated list of sentences..\n",
      "['But the staff was so horrible to us.', \"To be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of Teodora.\", \"The food is uniformly exceptional, with a very capable kitchen which will proudly whip up whatever you feel like eating, whether it's on the menu or not.\", 'Where Gabriela personaly greets you and recommends you what to eat.', \"For those that go once and don't enjoy it, all I can say is that they just don't get it.\"]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "print('Processing text dataset')\n",
    "\n",
    "tree = ET.parse(\"/home/jeet/Academics/CS671/Project/Restaurants_Train.xml\")\n",
    "corpus = tree.getroot()\n",
    "sentences = [] # List of sentences.\n",
    "raw_data = corpus.findall('.//sentence')\n",
    "for sent in raw_data:\n",
    "    sentences.append(sent.find('text').text)\n",
    "\n",
    "print ('Generated list of sentences..')\n",
    "print (sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Test data in unicode format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'But', u'the', u'staff', u'was', u'so', u'horrible', u'to', u'us']\n",
      "[u'To', u'be', u'completely', u'fair', u'the', u'only', u'redeeming', u'factor', u'was', u'the', u'food', u'which', u'was', u'above', u'average', u'but', u\"couldn't\", u'make', u'up', u'for', u'all', u'the', u'other', u'deficiencies', u'of', u'Teodora']\n",
      "[u'The', u'food', u'is', u'uniformly', u'exceptional', u'with', u'a', u'very', u'capable', u'kitchen', u'which', u'will', u'proudly', u'whip', u'up', u'whatever', u'you', u'feel', u'like', u'eating', u'whether', u\"it's\", u'on', u'the', u'menu', u'or', u'not']\n",
      "[u'Where', u'Gabriela', u'personaly', u'greets', u'you', u'and', u'recommends', u'you', u'what', u'to', u'eat']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "test_data = []\n",
    "count = 1\n",
    "for sent in sentences:\n",
    "    word_tokens = text_to_word_sequence(sent, lower=False)\n",
    "    word_tokens = [w.decode('UTF-8') for w in word_tokens]\n",
    "    if count < 5:\n",
    "        print word_tokens\n",
    "    count+=1\n",
    "    test_data.append(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of output tensor:', (3044, 69))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: FutureWarning: The behavior of this method will change in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "test_data = []\n",
    "train_out= np.zeros(shape=(3044,69))\n",
    "i=0\n",
    "for output in raw_data:\n",
    "    indices = np.zeros(69)\n",
    "    \n",
    "    aspectTerms = output.find('aspectTerms')\n",
    "    if (aspectTerms):\n",
    "        aspectTerm = aspectTerms.findall('aspectTerm')\n",
    "        if (aspectTerm):\n",
    "            for aspect_term in aspectTerm:\n",
    "                try:\n",
    "                    indices[s.index(aspect_term.attrib['term'])] = 1\n",
    "#                     print (indices)\n",
    "                except:\n",
    "                    continue\n",
    "    train_out[i] = indices\n",
    "    i=i+1\n",
    "\n",
    "print (\"Shape of output tensor:\", train_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Defining input data for CRF Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "i = 0\n",
    "for sent in sentences:\n",
    "    tuple_sent = []\n",
    "    word_token = text_to_word_sequence(sent, lower=False)\n",
    "    j = 0\n",
    "    for word in word_token:\n",
    "        input_tuple = ()\n",
    "        input_tuple = input_tuple + (word.decode('UTF-8'),)\n",
    "        if train_out[i][j] == 0:\n",
    "            input_tuple = input_tuple + ('NA',)\n",
    "        else:\n",
    "            input_tuple = input_tuple + ('A',)\n",
    "        tuple_sent.append(input_tuple)\n",
    "        j=j+1\n",
    "    train_input.append(tuple_sent)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Defining training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_input[:2739]\n",
    "test = test_data[2739:]\n",
    "true_test = train_input[2739:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "ct = CRFTagger()\n",
    "\n",
    "ct.train(train_data,'model_Crf_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.tag_sents(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.evaluate(true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
