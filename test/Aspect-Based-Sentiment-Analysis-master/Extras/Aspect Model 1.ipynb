{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 730M (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inp = pickle.load(open(\"train_inp.pkl\", \"rb\"))\n",
    "train_out = pickle.load(open(\"train_out.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(100, 2, border_mode=\"same\", input_shape=(80, 345)))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(MaxPooling1D(pool_length=5))\n",
    "model.add(Convolution1D(50, 3, border_mode=\"same\"))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"tanh\"))\n",
    "# softmax classifier\n",
    "model.add(Dense(80, W_regularizer=l2(0.01)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2891 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "2891/2891 [==============================] - 5s - loss: 3.5208 - acc: 0.1370 - val_loss: 2.2272 - val_acc: 0.1242\n",
      "Epoch 2/100\n",
      "2891/2891 [==============================] - 4s - loss: 2.8955 - acc: 0.1712 - val_loss: 2.1355 - val_acc: 0.1438\n",
      "Epoch 3/100\n",
      "2891/2891 [==============================] - 4s - loss: 2.7284 - acc: 0.2086 - val_loss: 2.0673 - val_acc: 0.2288\n",
      "Epoch 4/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.6444 - acc: 0.2421 - val_loss: 2.0923 - val_acc: 0.2484\n",
      "Epoch 5/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.5835 - acc: 0.2601 - val_loss: 2.1263 - val_acc: 0.1961\n",
      "Epoch 6/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.5349 - acc: 0.2816 - val_loss: 2.0040 - val_acc: 0.2288\n",
      "Epoch 7/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.4820 - acc: 0.2937 - val_loss: 2.0332 - val_acc: 0.3660\n",
      "Epoch 8/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.4418 - acc: 0.3013 - val_loss: 2.0207 - val_acc: 0.2288\n",
      "Epoch 9/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.3996 - acc: 0.3155 - val_loss: 1.9552 - val_acc: 0.2549\n",
      "Epoch 10/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.3619 - acc: 0.3269 - val_loss: 1.9724 - val_acc: 0.2418\n",
      "Epoch 11/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.3202 - acc: 0.3307 - val_loss: 1.9364 - val_acc: 0.2614\n",
      "Epoch 12/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.2843 - acc: 0.3265 - val_loss: 1.9457 - val_acc: 0.3856\n",
      "Epoch 13/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.2488 - acc: 0.3369 - val_loss: 1.9138 - val_acc: 0.2810\n",
      "Epoch 14/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.2175 - acc: 0.3383 - val_loss: 1.8816 - val_acc: 0.2549\n",
      "Epoch 15/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.1893 - acc: 0.3400 - val_loss: 1.8615 - val_acc: 0.2745\n",
      "Epoch 16/100\n",
      "2891/2891 [==============================] - 4s - loss: 2.1580 - acc: 0.3442 - val_loss: 1.8280 - val_acc: 0.3268\n",
      "Epoch 17/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.1370 - acc: 0.3404 - val_loss: 1.8487 - val_acc: 0.2157\n",
      "Epoch 18/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.1078 - acc: 0.3514 - val_loss: 1.8509 - val_acc: 0.2484\n",
      "Epoch 19/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.0861 - acc: 0.3383 - val_loss: 1.8783 - val_acc: 0.2680\n",
      "Epoch 20/100\n",
      "2891/2891 [==============================] - 4s - loss: 2.0664 - acc: 0.3449 - val_loss: 1.8633 - val_acc: 0.2941\n",
      "Epoch 21/100\n",
      "2891/2891 [==============================] - 4s - loss: 2.0431 - acc: 0.3397 - val_loss: 1.8051 - val_acc: 0.2484\n",
      "Epoch 22/100\n",
      "2891/2891 [==============================] - 5s - loss: 2.0240 - acc: 0.3449 - val_loss: 1.8380 - val_acc: 0.2484\n",
      "Epoch 23/100\n",
      "2891/2891 [==============================] - 4s - loss: 2.0023 - acc: 0.3494 - val_loss: 1.8496 - val_acc: 0.2484\n",
      "Epoch 24/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.9832 - acc: 0.3487 - val_loss: 1.9188 - val_acc: 0.2418\n",
      "Epoch 25/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.9685 - acc: 0.3487 - val_loss: 1.8464 - val_acc: 0.2484\n",
      "Epoch 26/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.9430 - acc: 0.3521 - val_loss: 1.8047 - val_acc: 0.2288\n",
      "Epoch 27/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.9281 - acc: 0.3501 - val_loss: 1.8183 - val_acc: 0.2353\n",
      "Epoch 28/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.9041 - acc: 0.3608 - val_loss: 1.8030 - val_acc: 0.2418\n",
      "Epoch 29/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.8877 - acc: 0.3514 - val_loss: 1.8174 - val_acc: 0.2026\n",
      "Epoch 30/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.8686 - acc: 0.3597 - val_loss: 1.8123 - val_acc: 0.2288\n",
      "Epoch 31/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.8477 - acc: 0.3639 - val_loss: 1.8357 - val_acc: 0.2157\n",
      "Epoch 32/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.8244 - acc: 0.3625 - val_loss: 1.7691 - val_acc: 0.2418\n",
      "Epoch 33/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.8117 - acc: 0.3604 - val_loss: 1.8196 - val_acc: 0.2353\n",
      "Epoch 34/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.7936 - acc: 0.3615 - val_loss: 1.8286 - val_acc: 0.2418\n",
      "Epoch 35/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.7762 - acc: 0.3667 - val_loss: 1.8162 - val_acc: 0.2680\n",
      "Epoch 36/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.7548 - acc: 0.3698 - val_loss: 1.8194 - val_acc: 0.2288\n",
      "Epoch 37/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.7355 - acc: 0.3750 - val_loss: 1.8077 - val_acc: 0.1830\n",
      "Epoch 38/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.7200 - acc: 0.3687 - val_loss: 1.7958 - val_acc: 0.1699\n",
      "Epoch 39/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.7007 - acc: 0.3743 - val_loss: 1.7669 - val_acc: 0.2288\n",
      "Epoch 40/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.6809 - acc: 0.3788 - val_loss: 1.8478 - val_acc: 0.1830\n",
      "Epoch 41/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.6620 - acc: 0.3767 - val_loss: 1.8077 - val_acc: 0.1961\n",
      "Epoch 42/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.6438 - acc: 0.3826 - val_loss: 1.8452 - val_acc: 0.1830\n",
      "Epoch 43/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.6276 - acc: 0.3833 - val_loss: 1.8164 - val_acc: 0.1765\n",
      "Epoch 44/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.6160 - acc: 0.3850 - val_loss: 1.8397 - val_acc: 0.1961\n",
      "Epoch 45/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.5978 - acc: 0.3909 - val_loss: 1.8045 - val_acc: 0.2092\n",
      "Epoch 46/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.5744 - acc: 0.3971 - val_loss: 1.7940 - val_acc: 0.1895\n",
      "Epoch 47/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.5626 - acc: 0.4002 - val_loss: 1.8203 - val_acc: 0.1895\n",
      "Epoch 48/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.5460 - acc: 0.4016 - val_loss: 1.8344 - val_acc: 0.2092\n",
      "Epoch 49/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.5295 - acc: 0.4061 - val_loss: 1.8518 - val_acc: 0.1699\n",
      "Epoch 50/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.5084 - acc: 0.4102 - val_loss: 1.7912 - val_acc: 0.1765\n",
      "Epoch 51/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.4952 - acc: 0.4033 - val_loss: 1.8666 - val_acc: 0.1569\n",
      "Epoch 52/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.4802 - acc: 0.4071 - val_loss: 1.8366 - val_acc: 0.1699\n",
      "Epoch 53/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.4688 - acc: 0.4161 - val_loss: 1.8433 - val_acc: 0.2026\n",
      "Epoch 54/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.4511 - acc: 0.4227 - val_loss: 1.8837 - val_acc: 0.1438\n",
      "Epoch 55/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.4360 - acc: 0.4196 - val_loss: 1.8972 - val_acc: 0.1569\n",
      "Epoch 56/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.4217 - acc: 0.4255 - val_loss: 1.8241 - val_acc: 0.1699\n",
      "Epoch 57/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.4086 - acc: 0.4279 - val_loss: 1.8546 - val_acc: 0.1765\n",
      "Epoch 58/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.3874 - acc: 0.4331 - val_loss: 1.8956 - val_acc: 0.1830\n",
      "Epoch 59/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.3755 - acc: 0.4262 - val_loss: 1.8992 - val_acc: 0.2157\n",
      "Epoch 60/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.3620 - acc: 0.4317 - val_loss: 1.8874 - val_acc: 0.1895\n",
      "Epoch 61/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.3449 - acc: 0.4331 - val_loss: 2.0309 - val_acc: 0.1438\n",
      "Epoch 62/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.3332 - acc: 0.4345 - val_loss: 1.8998 - val_acc: 0.1830\n",
      "Epoch 63/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.3194 - acc: 0.4386 - val_loss: 1.8752 - val_acc: 0.1569\n",
      "Epoch 64/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.3031 - acc: 0.4414 - val_loss: 1.9289 - val_acc: 0.1961\n",
      "Epoch 65/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2923 - acc: 0.4459 - val_loss: 1.9035 - val_acc: 0.1569\n",
      "Epoch 66/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2842 - acc: 0.4455 - val_loss: 1.8966 - val_acc: 0.1503\n",
      "Epoch 67/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.2675 - acc: 0.4417 - val_loss: 1.9635 - val_acc: 0.1634\n",
      "Epoch 68/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2554 - acc: 0.4466 - val_loss: 1.9208 - val_acc: 0.1503\n",
      "Epoch 69/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2433 - acc: 0.4542 - val_loss: 1.9414 - val_acc: 0.1634\n",
      "Epoch 70/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2327 - acc: 0.4590 - val_loss: 1.9518 - val_acc: 0.1569\n",
      "Epoch 71/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2202 - acc: 0.4504 - val_loss: 2.0190 - val_acc: 0.1961\n",
      "Epoch 72/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.2110 - acc: 0.4621 - val_loss: 1.9792 - val_acc: 0.1569\n",
      "Epoch 73/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.2002 - acc: 0.4559 - val_loss: 2.0025 - val_acc: 0.2026\n",
      "Epoch 74/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1881 - acc: 0.4652 - val_loss: 2.0232 - val_acc: 0.1634\n",
      "Epoch 75/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1789 - acc: 0.4587 - val_loss: 1.9693 - val_acc: 0.1830\n",
      "Epoch 76/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1680 - acc: 0.4621 - val_loss: 1.9872 - val_acc: 0.1569\n",
      "Epoch 77/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1572 - acc: 0.4711 - val_loss: 1.9760 - val_acc: 0.1634\n",
      "Epoch 78/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1465 - acc: 0.4618 - val_loss: 2.0197 - val_acc: 0.1438\n",
      "Epoch 79/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.1378 - acc: 0.4625 - val_loss: 2.0007 - val_acc: 0.1634\n",
      "Epoch 80/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1275 - acc: 0.4656 - val_loss: 2.0260 - val_acc: 0.1569\n",
      "Epoch 81/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1202 - acc: 0.4649 - val_loss: 1.9586 - val_acc: 0.1830\n",
      "Epoch 82/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.1099 - acc: 0.4670 - val_loss: 2.0811 - val_acc: 0.1830\n",
      "Epoch 83/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.1011 - acc: 0.4742 - val_loss: 2.0325 - val_acc: 0.1830\n",
      "Epoch 84/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0911 - acc: 0.4704 - val_loss: 1.9750 - val_acc: 0.1503\n",
      "Epoch 85/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0834 - acc: 0.4801 - val_loss: 2.0223 - val_acc: 0.1634\n",
      "Epoch 86/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.0775 - acc: 0.4742 - val_loss: 2.0758 - val_acc: 0.1830\n",
      "Epoch 87/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0697 - acc: 0.4742 - val_loss: 2.0236 - val_acc: 0.1503\n",
      "Epoch 88/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0624 - acc: 0.4735 - val_loss: 2.0170 - val_acc: 0.1634\n",
      "Epoch 89/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0530 - acc: 0.4753 - val_loss: 2.0124 - val_acc: 0.1634\n",
      "Epoch 90/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0435 - acc: 0.4756 - val_loss: 2.0652 - val_acc: 0.1634\n",
      "Epoch 91/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0402 - acc: 0.4773 - val_loss: 2.0640 - val_acc: 0.1569\n",
      "Epoch 92/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0327 - acc: 0.4784 - val_loss: 2.0779 - val_acc: 0.1307\n",
      "Epoch 93/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0227 - acc: 0.4728 - val_loss: 2.0585 - val_acc: 0.1438\n",
      "Epoch 94/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0190 - acc: 0.4801 - val_loss: 2.0780 - val_acc: 0.1569\n",
      "Epoch 95/100\n",
      "2891/2891 [==============================] - 5s - loss: 1.0114 - acc: 0.4784 - val_loss: 2.0630 - val_acc: 0.1503\n",
      "Epoch 96/100\n",
      "2891/2891 [==============================] - 4s - loss: 1.0064 - acc: 0.4794 - val_loss: 2.0798 - val_acc: 0.1634\n",
      "Epoch 97/100\n",
      "2891/2891 [==============================] - 4s - loss: 0.9999 - acc: 0.4794 - val_loss: 2.1006 - val_acc: 0.1438\n",
      "Epoch 98/100\n",
      "2891/2891 [==============================] - 4s - loss: 0.9942 - acc: 0.4791 - val_loss: 2.1343 - val_acc: 0.1569\n",
      "Epoch 99/100\n",
      "2891/2891 [==============================] - 4s - loss: 0.9893 - acc: 0.4818 - val_loss: 2.0773 - val_acc: 0.1503\n",
      "Epoch 100/100\n",
      "2891/2891 [==============================] - 4s - loss: 0.9806 - acc: 0.4742 - val_loss: 2.0809 - val_acc: 0.1569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb51d50fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inp, train_out,\n",
    "          validation_split=0.05,\n",
    "          batch_size=10,\n",
    "          nb_epoch=100\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking : expected convolution1d_input_7 to have 3 dimensions, but got array with shape (3044, 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f42cf6ea5558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         x = standardize_input_data(x, self.input_names,\n\u001b[1;32m   1158\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                                    check_batch_dim=False)\n\u001b[0m\u001b[1;32m   1160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     95\u001b[0m                                 \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                                 str(array.shape))\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking : expected convolution1d_input_7 to have 3 dimensions, but got array with shape (3044, 80)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
